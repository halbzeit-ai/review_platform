#!/bin/bash

# Claude Development Helper Script
# This script provides common development tasks for Claude Code to use

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

case "$1" in
    migrate)
        if [ -z "$2" ]; then
            echo -e "${RED}‚ùå Please provide migration file path${NC}"
            echo "Usage: $0 migrate migrations/filename.sql"
            exit 1
        fi
        
        if [ ! -f "$2" ]; then
            echo -e "${RED}‚ùå Migration file not found: $2${NC}"
            exit 1
        fi
        
        echo -e "${YELLOW}Running migration: $2${NC}"
        sudo -u postgres psql review-platform -f "$2"
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}‚úÖ Migration completed successfully${NC}"
        else
            echo -e "${RED}‚ùå Migration failed${NC}"
            exit 1
        fi
        ;;
    
    migrate-check)
        echo -e "${YELLOW}Checking database schema...${NC}"
        sudo -u postgres psql review-platform -c "\d project_documents" | grep -E "(Column|file_name)" || echo "No file_name column found"
        ;;
    
    db-connect)
        echo -e "${YELLOW}Connecting to database as postgres user...${NC}"
        sudo -u postgres psql review-platform
        ;;
    
    query)
        if [ -z "$2" ]; then
            echo -e "${RED}‚ùå Please provide SQL query${NC}"
            echo "Usage: $0 query \"SELECT * FROM table_name;\""
            exit 1
        fi
        
        echo -e "${YELLOW}Running query...${NC}"
        sudo -u postgres psql review-platform -c "$2"
        ;;
    
    db-check)
        echo -e "${YELLOW}Testing database connection...${NC}"
        cd /opt/review-platform-dev/backend
        python -c "
from app.db.database import SessionLocal
from app.db.models import PitchDeck
from sqlalchemy import text
db = SessionLocal()
try:
    # Test basic connection
    result = db.execute(text('SELECT 1')).fetchone()
    print('‚úÖ Database connection successful')
    
    # Check dojo files count
    dojo_count = db.query(PitchDeck).filter(PitchDeck.data_source == 'dojo').count()
    print(f'üìÅ Found {dojo_count} dojo files in database')
    
    # Check if zip_filename column exists
    try:
        result = db.execute(text(\"SELECT column_name FROM information_schema.columns WHERE table_name='pitch_decks' AND column_name='zip_filename'\")).fetchone()
        if result:
            print('‚úÖ zip_filename column exists')
        else:
            print('‚ùå zip_filename column does not exist - migration needed')
    except Exception as e:
        print(f'‚ö†Ô∏è  Could not check zip_filename column: {e}')
        
except Exception as e:
    print(f'‚ùå Database connection failed: {e}')
finally:
    db.close()
"
        ;;
    
    services)
        # Delegate to dev-services.sh
        if [ -f "/opt/review-platform-dev/dev-services.sh" ]; then
            /opt/review-platform-dev/dev-services.sh $2
        else
            echo -e "${RED}‚ùå dev-services.sh not found${NC}"
            exit 1
        fi
        ;;
    
    quick-test)
        echo -e "${YELLOW}Running quick development test...${NC}"
        
        # Check services
        echo -e "${BLUE}1. Checking services...${NC}"
        /opt/review-platform-dev/dev-services.sh status
        
        # Check database
        echo -e "${BLUE}2. Checking database...${NC}"
        $0 db-check
        
        # Check key endpoints
        echo -e "${BLUE}3. Testing key endpoints...${NC}"
        echo -n "Dojo files endpoint: "
        if curl -s http://localhost:5001/api/dojo/files > /dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ Working${NC}"
        else
            echo -e "${RED}‚ùå Failed${NC}"
        fi
        
        echo -n "Dojo stats endpoint: "
        if curl -s http://localhost:5001/api/dojo/stats > /dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ Working${NC}"
        else
            echo -e "${RED}‚ùå Failed${NC}"
        fi
        ;;
    
    git-status)
        echo -e "${YELLOW}Git status summary...${NC}"
        cd /opt/review-platform-dev
        echo -e "${BLUE}Current branch:${NC}"
        git branch --show-current
        echo -e "${BLUE}Uncommitted changes:${NC}"
        git status --porcelain | wc -l | xargs echo "Files changed:"
        echo -e "${BLUE}Recent commits:${NC}"
        git log --oneline -5
        ;;
    
    gpu-logs)
        GPU_LOG_PATH="/mnt/dev-shared/logs/gpu_processing.log"
        if [ "$2" = "tail" ] || [ -z "$2" ]; then
            echo -e "${YELLOW}Following GPU processing logs...${NC}"
            echo -e "${BLUE}Log path: $GPU_LOG_PATH${NC}"
            echo -e "${BLUE}Press Ctrl+C to exit${NC}"
            tail -f "$GPU_LOG_PATH" 2>/dev/null || echo -e "${RED}‚ùå GPU log file not found. Is GPU service running?${NC}"
        elif [ "$2" = "errors" ]; then
            echo -e "${YELLOW}GPU processing errors and warnings...${NC}"
            if [ -f "$GPU_LOG_PATH" ]; then
                grep -E "(ERROR|WARNING|ValueError|Exception)" "$GPU_LOG_PATH" | tail -20
            else
                echo -e "${RED}‚ùå GPU log file not found${NC}"
            fi
        elif [ "$2" = "backend" ]; then
            echo -e "${YELLOW}GPU backend URL configuration...${NC}"
            if [ -f "$GPU_LOG_PATH" ]; then
                grep -E "(Using backend server|BACKEND_DEVELOPMENT|cache.*analysis)" "$GPU_LOG_PATH" | tail -10
            else
                echo -e "${RED}‚ùå GPU log file not found${NC}"
            fi
        elif [ "$2" = "cache" ]; then
            echo -e "${YELLOW}GPU cache operations...${NC}"
            if [ -f "$GPU_LOG_PATH" ]; then
                grep -E "(cache.*analysis|Failed to cache|Successfully cached)" "$GPU_LOG_PATH" | tail -20
            else
                echo -e "${RED}‚ùå GPU log file not found${NC}"
            fi
        else
            echo -e "${YELLOW}Last 50 lines of GPU logs...${NC}"
            if [ -f "$GPU_LOG_PATH" ]; then
                tail -50 "$GPU_LOG_PATH"
            else
                echo -e "${RED}‚ùå GPU log file not found${NC}"
            fi
        fi
        ;;
    
    debug-cache)
        echo -e "${YELLOW}Debugging visual analysis caching issue...${NC}"
        
        echo -e "${BLUE}1. Checking backend cache endpoint logs...${NC}"
        grep -E "(cache-visual-analysis|GPU caching)" /opt/review-platform-dev/backend/backend.log | tail -5 || echo "No cache operations found in backend logs"
        
        echo -e "${BLUE}2. Checking GPU backend URL configuration...${NC}"
        GPU_LOG_PATH="/mnt/dev-shared/logs/gpu_processing.log"
        if [ -f "$GPU_LOG_PATH" ]; then
            grep -E "(Using backend server|BACKEND_DEVELOPMENT|ValueError.*BACKEND)" "$GPU_LOG_PATH" | tail -3 || echo "No backend URL info found"
        else
            echo "GPU log file not found - GPU service may not be running"
        fi
        
        echo -e "${BLUE}3. Checking visual analysis cache database entries...${NC}"
        $0 query "SELECT COUNT(*) as cached_analyses, MAX(created_at) as latest_cache FROM visual_analysis_cache;"
        
        echo -e "${BLUE}4. Recent deck processing...${NC}"
        if [ -f "$GPU_LOG_PATH" ]; then
            grep -E "Processing deck.*with template" "$GPU_LOG_PATH" | tail -5 || echo "No recent deck processing found"
        fi
        ;;
    
    cache-check)
        echo -e "${YELLOW}Visual analysis cache status...${NC}"
        $0 query "SELECT document_id, vision_model_used, created_at FROM visual_analysis_cache ORDER BY created_at DESC LIMIT 10;" 
        ;;
    
    verify-cleanup)
        echo -e "${YELLOW}üîç Comprehensive Database Cleanup Verification${NC}"
        echo -e "${BLUE}This command verifies that all legacy data has been properly cleaned up${NC}"
        echo ""
        
        # Function to run database query
        run_query() {
            local query="$1"
            local description="$2"
            echo -e "${BLUE}Checking: $description${NC}"
            sudo -u postgres psql review-platform -c "$query"
            echo ""
        }
        
        # 1. Check extraction_experiments table
        echo -e "${YELLOW}1. Extraction Experiments Cleanup${NC}"
        run_query "SELECT COUNT(*) as total_extraction_experiments FROM extraction_experiments;" "Total extraction experiments"
        run_query "SELECT id, experiment_name, document_ids, created_at FROM extraction_experiments ORDER BY created_at DESC LIMIT 5;" "Recent extraction experiments (should be empty)"
        
        # 2. Check visual_analysis_cache for any legacy data
        echo -e "${YELLOW}2. Visual Analysis Cache Status${NC}"
        run_query "SELECT COUNT(*) as total_cached_analyses FROM visual_analysis_cache;" "Total cached visual analyses"
        run_query "SELECT document_id, vision_model_used, created_at FROM visual_analysis_cache ORDER BY created_at DESC LIMIT 5;" "Recent visual analyses"
        
        # 3. Check processing_queue for any stuck tasks
        echo -e "${YELLOW}3. Processing Queue Health${NC}"
        run_query "SELECT status, COUNT(*) as count FROM processing_queue GROUP BY status;" "Queue status breakdown"
        run_query "SELECT id, document_id, status, progress_percentage, current_step FROM processing_queue WHERE status IN ('processing', 'queued') ORDER BY created_at DESC LIMIT 5;" "Active/queued tasks"
        
        # 4. Check project_documents table consistency
        echo -e "${YELLOW}4. Project Documents Consistency${NC}"
        run_query "SELECT processing_status, COUNT(*) as count FROM project_documents GROUP BY processing_status;" "Document processing status breakdown"
        run_query "SELECT id, file_name, processing_status, upload_date FROM project_documents WHERE processing_status = 'processing' ORDER BY upload_date DESC LIMIT 5;" "Documents stuck in processing"
        
        # 5. Check for any orphaned data relationships
        echo -e "${YELLOW}5. Data Relationship Integrity${NC}"
        run_query "SELECT COUNT(*) as orphaned_visual_cache FROM visual_analysis_cache v LEFT JOIN project_documents pd ON v.document_id = pd.id WHERE pd.id IS NULL;" "Orphaned visual analysis cache entries"
        run_query "SELECT COUNT(*) as orphaned_queue_tasks FROM processing_queue pq LEFT JOIN project_documents pd ON pq.document_id = pd.id WHERE pd.id IS NULL;" "Orphaned processing queue tasks"
        
        # 6. Summary and recommendations
        echo -e "${YELLOW}6. Cleanup Verification Summary${NC}"
        echo -e "${GREEN}‚úÖ Verification complete. Check the results above:${NC}"
        echo -e "${BLUE}  ‚Ä¢ extraction_experiments should be 0 rows${NC}"
        echo -e "${BLUE}  ‚Ä¢ No documents should be stuck in 'processing' status${NC}"
        echo -e "${BLUE}  ‚Ä¢ No orphaned cache or queue entries${NC}"
        echo -e "${BLUE}  ‚Ä¢ Processing queue should be healthy${NC}"
        ;;
    
    cleanup-extraction-data)
        echo -e "${YELLOW}üóëÔ∏è COMPREHENSIVE Extraction Data Cleanup${NC}"
        echo -e "${RED}‚ö†Ô∏è  WARNING: This will permanently delete ALL extraction and analysis data${NC}"
        echo -e "${BLUE}This includes:${NC}"
        echo -e "${BLUE}  ‚Ä¢ extraction_experiments (extraction results, classification, company names, funding, dates)${NC}"
        echo -e "${BLUE}  ‚Ä¢ specialized_analysis_results (clinical, regulatory, scientific analysis)${NC}"
        echo -e "${BLUE}  ‚Ä¢ visual_analysis_cache (cached visual analysis results)${NC}"
        echo -e "${BLUE}  ‚Ä¢ question_analysis_results (template question analysis)${NC}"
        echo -e "${BLUE}  ‚Ä¢ chapter_analysis_results (template chapter analysis)${NC}"
        echo ""
        
        read -p "Are you sure you want to proceed? (type 'yes' to confirm): " confirm
        if [ "$confirm" != "yes" ]; then
            echo -e "${BLUE}Cleanup cancelled${NC}"
            exit 0
        fi
        
        echo -e "${YELLOW}Performing COMPREHENSIVE extraction data cleanup...${NC}"
        
        # 1. Show what will be deleted from each table
        echo -e "${BLUE}üìä Current data counts before cleanup:${NC}"
        sudo -u postgres psql review-platform -c "
            SELECT 'extraction_experiments' as table_name, COUNT(*) as count FROM extraction_experiments
            UNION ALL
            SELECT 'specialized_analysis_results', COUNT(*) FROM specialized_analysis_results  
            UNION ALL
            SELECT 'visual_analysis_cache', COUNT(*) FROM visual_analysis_cache
            UNION ALL
            SELECT 'question_analysis_results', COUNT(*) FROM question_analysis_results
            UNION ALL
            SELECT 'chapter_analysis_results', COUNT(*) FROM chapter_analysis_results
            ORDER BY table_name;
        "
        
        echo ""
        echo -e "${YELLOW}üóëÔ∏è Starting comprehensive cleanup...${NC}"
        
        # 2. Delete from all extraction/analysis tables
        echo -e "${BLUE}Deleting extraction_experiments...${NC}"
        sudo -u postgres psql review-platform -c "DELETE FROM extraction_experiments;"
        
        echo -e "${BLUE}Deleting specialized_analysis_results...${NC}"
        sudo -u postgres psql review-platform -c "DELETE FROM specialized_analysis_results;"
        
        echo -e "${BLUE}Deleting visual_analysis_cache...${NC}"
        sudo -u postgres psql review-platform -c "DELETE FROM visual_analysis_cache;"
        
        echo -e "${BLUE}Deleting question_analysis_results...${NC}"
        sudo -u postgres psql review-platform -c "DELETE FROM question_analysis_results;"
        
        echo -e "${BLUE}Deleting chapter_analysis_results...${NC}"
        sudo -u postgres psql review-platform -c "DELETE FROM chapter_analysis_results;"
        
        echo -e "${GREEN}‚úÖ All extraction and analysis data deleted${NC}"
        
        # 3. Verify cleanup with counts
        echo ""
        echo -e "${YELLOW}üìä Verification - data counts after cleanup:${NC}"
        sudo -u postgres psql review-platform -c "
            SELECT 'extraction_experiments' as table_name, COUNT(*) as remaining_count FROM extraction_experiments
            UNION ALL
            SELECT 'specialized_analysis_results', COUNT(*) FROM specialized_analysis_results  
            UNION ALL
            SELECT 'visual_analysis_cache', COUNT(*) FROM visual_analysis_cache
            UNION ALL
            SELECT 'question_analysis_results', COUNT(*) FROM question_analysis_results
            UNION ALL
            SELECT 'chapter_analysis_results', COUNT(*) FROM chapter_analysis_results
            ORDER BY table_name;
        "
        
        # 4. Run comprehensive verification
        echo ""
        echo -e "${YELLOW}üîç Running comprehensive system verification...${NC}"
        $0 verify-cleanup
        
        echo ""
        echo -e "${GREEN}‚úÖ COMPREHENSIVE extraction data cleanup completed${NC}"
        echo -e "${GREEN}‚úÖ All extraction results should now be removed from UI${NC}"
        ;;
    
    *)
        echo -e "${BLUE}Claude Development Helper${NC}"
        echo ""
        echo "Database Commands:"
        echo "  migrate <file>     - Run database migration with elevated privileges"
        echo "  query \"SQL\"        - Run SQL query on database"
        echo "  migrate-check      - Check if zip_filename column exists"
        echo "  db-connect         - Connect to database as postgres user"
        echo "  db-check          - Test database connection and show info"
        echo ""
        echo "Service Commands:"
        echo "  services <cmd>     - Run dev-services.sh commands (start|stop|restart|status|logs)"
        echo ""
        echo "Development Commands:"
        echo "  quick-test         - Run comprehensive development test"
        echo "  git-status         - Show git status summary"
        echo ""
        echo "GPU & Cache Debugging:"
        echo "  gpu-logs [tail]    - Follow GPU processing logs in real-time"
        echo "  gpu-logs errors    - Show recent GPU errors and warnings"
        echo "  gpu-logs backend   - Show GPU backend URL configuration"
        echo "  gpu-logs cache     - Show GPU caching operations"
        echo "  debug-cache        - Comprehensive cache debugging analysis"
        echo "  cache-check        - Check visual analysis cache database status"
        echo ""
        echo "Data Cleanup & Verification:"
        echo "  verify-cleanup     - Comprehensive verification that cleanup was successful"
        echo "  cleanup-extraction-data - DANGER: Permanently delete all extraction experiment data"
        echo ""
        echo "Examples:"
        echo "  $0 migrate migrations/add_zip_filename_to_pitch_decks.sql"
        echo "  $0 services start"
        echo "  $0 gpu-logs tail"
        echo "  $0 debug-cache"
        echo "  $0 cache-check"
        echo "  $0 verify-cleanup"
        echo "  $0 cleanup-extraction-data"
        ;;
esac